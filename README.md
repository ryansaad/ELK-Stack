# ELK-Stack

# ELK Stack for Real-time Application Log Monitoring

## Project Overview

This project demonstrates the end-to-end setup of the **ELK Stack (Elasticsearch, Logstash, Kibana)** and **Filebeat** to collect, process, and visualize real-time logs from a running application. It provides a complete log monitoring and observability solution from scratch.


## Key Features

* **Real-time Log Collection:** Utilizes **Filebeat** as a lightweight agent to tail log files from the application server and forward them to the central monitoring server.
* **Data Processing & Structuring:** **Logstash** receives raw log data and processes it using **Grok filters** to convert unstructured log data into a clean, structured format.
* **Efficient Indexing & Storage:** **Elasticsearch** indexes the structured data, making it searchable and enabling fast data retrieval for analysis.
* **Interactive Visualization & Dashboards:** **Kibana** provides a web-based interface to visualize logs through charts, graphs, and customizable dashboards for real-time monitoring and analysis.
* **End-to-End Monitoring:** Sets up a complete pipeline to monitor application logs, aiding in troubleshooting and performance analysis.


## Technologies Used

* **Elasticsearch:** The core component of the stack, serving as a distributed search and analytics engine to store and index the log data for fast retrieval.
* **Logstash:** Used as the data processing pipeline to receive raw logs from Filebeat, parse them, and transform them into a structured format using **Grok filters** before sending them to Elasticsearch.
* **Kibana:** The visualization layer of the stack, providing a web-based UI to query Elasticsearch data, create interactive dashboards, charts, and graphs for log monitoring and analysis.
* **Filebeat:** A lightweight data shipper that is installed on the application server to collect log data from a specified file (`app.log`) and forward it to Logstash.
* **Java:** The programming language used for the sample application whose logs are being monitored.
* **AWS EC2:** The cloud platform used to provision the virtual machines for both the ELK stack and the application server.
* **Maven:** Used to build and package the Java application into a runnable JAR file.



## Architecture / Workflow

The log monitoring system follows a clear, multi-stage pipeline:

1.  **Log Generation & Collection:** The application running on the server generates logs and writes them to a local file (e.g., `app.log`). **Filebeat**, a lightweight agent installed on the same server, tails this log file and forwards the raw data.
2.  **Data Ingestion & Processing:** The raw log data is sent to **Logstash**, which acts as a data processing pipeline. It uses **Grok filters** to parse the unstructured log entries, converting them into a structured, machine-readable format.
3.  **Indexing & Storage:** The structured data is then sent to **Elasticsearch**. Elasticsearch indexes this data, storing it in a scalable and searchable format that allows for very fast queries.
4.  **Visualization & Analysis:** **Kibana** connects to **Elasticsearch** to retrieve the indexed data. It provides a web-based interface for users to visualize the logs in real-time through charts, graphs, and customizable dashboards.



## Challenges and Solutions

* **Filebeat Installation on Ubuntu:**
    * **Challenge:** When attempting to install **Filebeat** using `sudo apt install filebeat`, the package was not found in the default Linux repositories.
    * **Solution:** Realized that Elastic products require their own separate repository to be added to the system's package list. Added the **Elastic repository and GPG key** using `wget` and `echo`, updated `apt`, and then the Filebeat package became available for installation.
* **Logstash Configuration File Debugging:**
    * **Challenge:** The Logstash configuration file is very sensitive to syntax and indentation errors, which can cause the service to fail to start without a clear error message.
    * **Solution:** Carefully edited the `logstash.conf` file, ensuring the correct indentation and format for the `input`, `filter`, and `output` blocks. This was key to getting the Logstash service running properly and accepting data from Filebeat.
* **Java Application JAR File Name Mismatch:**
    * **Challenge:** The application failed to start with a `java -jar` command because the hardcoded JAR file name in the command (`app.jar`) did not match the actual file name generated by Maven (`database-service_project.jar`).
    * **Solution:** Diagnosed the issue by checking the build output and the contents of the `target` directory. Updated the `java -jar` command to use the correct JAR file name, which allowed the application to run successfully and start generating logs.
* **Filebeat Output Configuration Errors:**
    * **Challenge:** After configuration, Filebeat failed to send logs, and `test output` commands in the console showed errors.
    * **Solution:** Debugged the `filebeat.yml` file, realizing that it had both Elasticsearch and Logstash outputs configured simultaneously. Commented out the Elasticsearch output section, leaving only the Logstash output, which resolved the issue and allowed logs to flow to Logstash.
* **Kibana Readiness Delay:**
    * **Challenge:** After starting the Kibana service, the web UI was not immediately accessible and showed a "not ready yet" message.
    * **Solution:** Understood that Kibana requires Elasticsearch to be fully initialized and ready before it can connect and function. Waited for a few minutes to allow Elasticsearch to start up completely, after which Kibana became accessible and functional.

---


